<!DOCTYPE HTML>
<html>
<head>
    <title>Module 1: Data Visualization - Unit 8</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <style>
        p {
            text-align: left; /* Aligns all paragraph text to the left */
        }
    </style>
</head>
<body class="is-preload">

    <!-- Navigation back to module -->
    <nav id="nav">
        <ul class="container">
            <li><a href="mod_6_main.html">Back to Module 6: Research Methods Learning</a></li>
        </ul>
    </nav>

    <!-- Unit Content -->
<article id="unit-content" class="wrapper style1">
    <div class="container">
        <section id="reflection">

<h2>Literature Review Planning and Feedback Reflection</h2>

<a href="docs\M6U4LiteratureReviewOutline.pdf"
   class="button large scrolly" target="_blank">
   View Literature Review Outline
</a>
<br><br>

<h3>What?</h3>
<p>
    For this formative task, I submitted an outline for my planned literature review on how large language models are being used in academic writing and learning support. The outline was built around a central question that keeps coming up in both research and practice, how these tools can support students without undermining academic integrity or independent thinking. I structured the review to move from the benefits of LLMs, such as feedback, accessibility, and efficiency, through to the risks around authorship, overreliance, bias, and institutional response.
</p>
<p>
    The feedback from my tutor acknowledged that the outline showed a strong grasp of the topic and that the structure made sense. At the same time, it pointed out that the plan was still too conceptual. In particular, it did not yet make clear which empirical studies would be used, how the literature would be selected, or how disagreements in the research would be handled. There was also a suggestion that some ethical themes overlapped and could be combined, and that the review would benefit from being more clearly grounded in real educational outcomes and international contexts.
</p>

<h3>So what?</h3>
<p>
    Reading this feedback was useful because it highlighted a gap between how I understand the topic and how I need to demonstrate that understanding academically. Much of the outline was shaped by my professional experience in education and assessment, where these debates are already very familiar. That made it easy to describe the issues, but the feedback made it clear that describing issues is not the same as controlling the literature.
</p>
<p>
    One comment that stood out was about contradictory evidence. A lot of the research on LLMs in education does not point in one clear direction. Some studies report improvements in writing quality or feedback, while others raise concerns about dependency or misconduct. I realised that I had assumed these tensions would naturally work themselves out during writing. The feedback helped me see that dealing with disagreement is something that needs to be planned, not postponed. It also made me reflect on my tendency to include everything rather than making clearer decisions about where deeper analysis is actually needed.
</p>

<h3>Now what?</h3>
<p>
    Going forward, I will revise the literature review plan to be much clearer about how evidence will be handled. This means explicitly identifying key empirical studies and explaining why they matter, particularly those that measure outcomes like writing performance, feedback quality, student behaviour, or integrity concerns. I will also add a short methodology section that explains how sources will be found, filtered, and compared, and how gaps or conflicting findings will be treated rather than glossed over.
</p>
<p>
    I also plan to simplify the structure by bringing overlapping ethical issues together into a more focused discussion. This should make it easier to move beyond listing risks and instead explore how these concerns actually interact in real educational settings. Overall, this feedback helped me shift from thinking about what I wanted to say, to thinking more carefully about how I will show critical judgement. Addressing these points early has made the direction of the final literature review feel much clearer and more manageable.
</p>

<h3>References</h3>
<ul>
    <li>Almoraie, A. and Alhejaili, M. (2025) ‘A systematic literature review to implement large language model in education’, <em>Education and Information Technologies</em>.</li>
    <li>Bittle, K. and El-Gayar, O. (2025) ‘Generative AI and academic integrity in higher education’, <em>Information</em>, 16(4), 296.</li>
    <li>Bretag, T. and Mahmud, S. (2016) ‘A conceptual framework for academic integrity policy’, in Bretag, T. (ed.) <em>Handbook of Academic Integrity</em>. Singapore: Springer.</li>
    <li>Kasneci, E. et al. (2023) ‘ChatGPT for good?’, <em>Learning and Individual Differences</em>, 104, 102274.</li>
    <li>Ramírez-Montoya, M.S. and Lugo-Ocando, D. (2024) ‘The impact of large language models on higher education’, <em>Frontiers in Education</em>, 9, 1392091.</li>
    <li>Zawacki-Richter, O. and Marín, V.I. (2024) ‘ChatGPT in higher education’, <em>Educational Technology Research and Development</em>.</li>
    <li>Driscoll, J. (2007) <em>Practising Clinical Supervision</em>. 2nd ed. Edinburgh: Elsevier.</li>
</ul>

        </section>
    </div>
</article>





            
            <!-- Buttons to open documents -->
            <footer>
                
            </footer>
        </div>
    </article>
</body>
</html>
